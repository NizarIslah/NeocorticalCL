{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43895ec1-52a7-43d4-acfb-360cc24c0ee2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nislah/.vmgr_repo/dev-2021-02-py38/lib/python3.8/site-packages/avalanche/training/plugins/evaluation.py:84: UserWarning: No benchmark provided to the evaluation plugin. Metrics may be computed on inconsistent portion of streams, use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Starting experiment...\n",
      "Start training on experience  0\n",
      "End training on experience  0\n",
      "Computing accuracy on the test set\n",
      "dict_iCaRL_aia=  {'Top1_Acc_Stream/Exp0': 0.128}\n",
      "scifar100-batch=10 Average Incremental Accuracy: 0.12800\n",
      "Start training on experience  1\n",
      "End training on experience  1\n",
      "Computing accuracy on the test set\n",
      "dict_iCaRL_aia=  {'Top1_Acc_Stream/Exp0': 0.128, 'Top1_Acc_Stream/Exp1': 0.1155}\n",
      "scifar100-batch=10 Average Incremental Accuracy: 0.12175\n",
      "Start training on experience  2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3608576/3933803529.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Start training on experience \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_batch_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_experience\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batch_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"End training on experience \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_batch_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_experience\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Computing accuracy on the test set'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.vmgr_repo/dev-2021-02-py38/lib/python3.8/site-packages/avalanche/training/strategies/base_strategy.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, experiences, eval_streams, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperience\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexperiences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperience\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_streams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.vmgr_repo/dev-2021-02-py38/lib/python3.8/site-packages/avalanche/training/strategies/base_strategy.py\u001b[0m in \u001b[0;36mtrain_exp\u001b[0;34m(self, experience, eval_streams, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_training_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_periodic_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_streams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_final\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.vmgr_repo/dev-2021-02-py38/lib/python3.8/site-packages/avalanche/training/strategies/base_strategy.py\u001b[0m in \u001b[0;36mtraining_epoch\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m             \u001b[0;31m# Loss & Backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_before_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.vmgr_repo/dev-2021-02-py38/lib/python3.8/site-packages/avalanche/training/strategies/base_strategy.py\u001b[0m in \u001b[0;36mcriterion\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;34m\"\"\" Loss function. \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmb_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmb_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     def train(self, experiences: Union[Experience, Sequence[Experience]],\n",
      "\u001b[0;32m~/.vmgr_repo/dev-2021-02-py38/lib/python3.8/site-packages/avalanche/training/losses.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, logits, targets)\u001b[0m\n\u001b[1;32m     36\u001b[0m         one_hot = torch.zeros(targets.shape[0], logits.shape[1],\n\u001b[1;32m     37\u001b[0m                               dtype=torch.float, device=logits.device)\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mone_hot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mold_logits\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "from torch.optim import SGD\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from avalanche.models import SimpleMLP, IncrementalClassifier\n",
    "from avalanche.training.strategies import Naive, CWRStar, Replay, GDumb, Cumulative, LwF, GEM, AGEM, EWC, CoPE\n",
    "from avalanche.benchmarks.classic import SplitMNIST\n",
    "from avalanche.training.strategies import BaseStrategy\n",
    "from avalanche.training.plugins import ReplayPlugin, EWCPlugin, GEMPlugin, GDumbPlugin\n",
    "from torch.optim import SGD\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from avalanche.benchmarks.classic import SplitMNIST, SplitCIFAR10, SplitCIFAR100\n",
    "from avalanche.evaluation.metrics import forgetting_metrics, accuracy_metrics, \\\n",
    "    loss_metrics, timing_metrics, cpu_usage_metrics, confusion_matrix_metrics, disk_usage_metrics,ExperienceForgetting\n",
    "from avalanche.models import SimpleMLP\n",
    "from avalanche.logging import InteractiveLogger, TextLogger, TensorboardLogger\n",
    "from avalanche.training.plugins import EvaluationPlugin\n",
    "from avalanche.training.strategies import Naive\n",
    "from pl_bolts.models.self_supervised import SwAV\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.optim import SGD\n",
    "from torchvision import transforms\n",
    "from avalanche.training.strategies.icarl import ICaRL\n",
    "import numpy as np\n",
    "from avalanche.benchmarks.classic.ccifar100 import SplitCIFAR100\n",
    "from avalanche.models import IcarlNet, make_icarl_net, initialize_icarl_net\n",
    "from avalanche.training.plugins.lr_scheduling import LRSchedulerPlugin\n",
    "\n",
    "from NeoCL.models.pretrained import PretrainedIncrementalClassifier, SSLIcarl\n",
    "from NeoCL.plugins.sparse_ewc import SparseEWCPlugin\n",
    "from NeoCL.strategies.utils import get_average_metric, create_default_args\n",
    "\n",
    "\n",
    "# create strategy\n",
    "def icarl_cifar100_augment_data(img):\n",
    "    img = img.numpy()\n",
    "    padded = np.pad(img, ((0, 0), (4, 4), (4, 4)), mode='constant')\n",
    "    random_cropped = np.zeros(img.shape, dtype=np.float32)\n",
    "    crop = np.random.randint(0, high=8 + 1, size=(2,))\n",
    "\n",
    "    # Cropping and possible flipping\n",
    "    if np.random.randint(2) > 0:\n",
    "        random_cropped[:, :, :] = \\\n",
    "            padded[:, crop[0]:(crop[0]+32), crop[1]:(crop[1]+32)]\n",
    "    else:\n",
    "        random_cropped[:, :, :] = \\\n",
    "            padded[:, crop[0]:(crop[0]+32), crop[1]:(crop[1]+32)][:, :, ::-1]\n",
    "    t = torch.tensor(random_cropped)\n",
    "    return t\n",
    "fixed_class_order = [87, 0, 52, 58, 44, 91, 68, 97, 51, 15,\n",
    "                            94, 92, 10, 72, 49, 78, 61, 14, 8, 86,\n",
    "                            84, 96, 18, 24, 32, 45, 88, 11, 4, 67,\n",
    "                            69, 66, 77, 47, 79, 93, 29, 50, 57, 83,\n",
    "                            17, 81, 41, 12, 37, 59, 25, 20, 80, 73,\n",
    "                            1, 28, 6, 46, 62, 82, 53, 9, 31, 75,\n",
    "                            38, 63, 33, 74, 27, 22, 36, 3, 16, 21,\n",
    "                            60, 19, 70, 90, 89, 43, 5, 42, 65, 76,\n",
    "                            40, 30, 23, 85, 2, 95, 56, 48, 71, 64,\n",
    "                            98, 13, 99, 7, 34, 55, 54, 26, 35, 39]\n",
    "# config (NOTE: memory_size==k)\n",
    "seed = np.random.randint(1000, 9999)\n",
    "args = create_default_args({'cuda': 0, 'batch_size': 128, 'nb_exp': 10,\n",
    "                            'memory_size': 2000, 'epochs': 70, 'lr_base': 2.,\n",
    "                            'lr_milestones': [49, 63], 'lr_factor': 5.,\n",
    "                            'wght_decay': 0.00001, 'train_mb_size': 256,\n",
    "                            'fixed_class_order': fixed_class_order, 'seed': seed})\n",
    "#\n",
    "device = torch.device(f\"cuda:{args.cuda}\"\n",
    "                      if torch.cuda.is_available() and\n",
    "                         args.cuda >= 0 else \"cpu\")\n",
    "weight_path = 'https://pl-bolts-weights.s3.us-east-2.amazonaws.com/swav/swav_imagenet/swav_imagenet.pth.tar'\n",
    "encoder = SwAV.load_from_checkpoint(weight_path, strict=True)\n",
    "encoder.freeze()\n",
    "model = SSLIcarl(encoder,embedding_size=2048,num_classes=100).to(device)\n",
    "tb_logger = TensorboardLogger(f'../logs/{seed}/')\n",
    "eval_plugin = EvaluationPlugin(\n",
    "    accuracy_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "    loss_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
    "    ExperienceForgetting(),\n",
    "    loggers=[tb_logger])\n",
    "benchmark = SplitCIFAR100(n_experiences=args.nb_exp, seed=args.seed,\n",
    "              fixed_class_order=args.fixed_class_order, dataset_root='/share/datasets/')\n",
    "\n",
    "\n",
    "optim = SGD(model.parameters(), lr=args.lr_base,\n",
    "            weight_decay=args.wght_decay, momentum=0.9)\n",
    "sched = LRSchedulerPlugin(\n",
    "    MultiStepLR(optim, args.lr_milestones, gamma=1.0 / args.lr_factor))\n",
    "\n",
    "strategy = ICaRL(\n",
    "    model.feature_extractor, model.classifier, optim,\n",
    "    args.memory_size,\n",
    "    buffer_transform=transforms.Compose([icarl_cifar100_augment_data]),\n",
    "    fixed_memory=True, train_mb_size=args.batch_size,\n",
    "    train_epochs=args.epochs, eval_mb_size=args.batch_size,\n",
    "    plugins=[sched], device=device, evaluator=eval_plugin\n",
    ")\n",
    "\n",
    "# train on the selected scenario with the chosen strategy\n",
    "print('Starting experiment...')\n",
    "dict_iCaRL_aia = {}\n",
    "for i, train_batch_info in enumerate(benchmark.train_stream):\n",
    "    print(\"Start training on experience \", train_batch_info.current_experience)\n",
    "\n",
    "    strategy.train(train_batch_info, num_workers=4)\n",
    "    print(\"End training on experience \", train_batch_info.current_experience)\n",
    "    print('Computing accuracy on the test set')\n",
    "    res = strategy.eval(benchmark.test_stream[:i + 1], num_workers=4)\n",
    "    dict_iCaRL_aia['Top1_Acc_Stream/Exp'+str(i)] = res['Top1_Acc_Stream/eval_phase/test_stream/Task000']\n",
    "    avg_ia = get_average_metric(dict_iCaRL_aia)\n",
    "    print(\"dict_iCaRL_aia= \", dict_iCaRL_aia)\n",
    "    print(f\"scifar100-batch=10 Average Incremental Accuracy: {avg_ia:.5f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b158903-eda0-4e92-87e3-47ba1fc945ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_ctrl(task_gen:TaskGenerator, task, args:ArgsGenerator, split=0, \n",
    "                            batch_size=64, num_batches=None, labeled=True, normalize=False, **kwargs):\n",
    "    single_head=(args.multihead=='none')\n",
    "    normalize=args.normalize_data\n",
    "    y = task.get_labels(split=split, prop=0)\n",
    "    x = task.get_data(split=split)\n",
    "    if labeled:\n",
    "        idx = torch.where(y!=-1)\n",
    "        y = y[idx]\n",
    "        x = x[idx]\n",
    "    if num_batches is not None:       \n",
    "        batch_size=int(len(y)//num_batches)\n",
    "    transform=None\n",
    "    \n",
    "    if x.shape[1]<task.x_dim[-1] and args.task_sequence=='s_mnist_svhn':\n",
    "        transform = transforms.Compose([ transforms.ToPILImage(),transforms.Resize((task.x_dim[-1],task.x_dim[-1])), ToTensor()])\n",
    "    if normalize:\n",
    "        if min(task.statistics['mean'])>0 and 'mnist' in str(task.concepts) and 'ood' in args.task_sequence: \n",
    "            #if no dimention is completely zeros we use statistics of the complete MNIST dataset (for simplisity) - will be used for task sequence s_ood_bkgrnd_white_digits\n",
    "            if transform is None:\n",
    "                transform = transforms.Normalize((0.1307,0.1307,0.1307), (0.3081,0.3081,0.3081))\n",
    "            else:\n",
    "                transform.append(transforms.Normalize((0.1307,0.1307,0.1307), (0.3081,0.3081,0.3081)))\n",
    "        else:\n",
    "            #we leave dimentions with only 0s to stay only 0s\n",
    "            if transform is None:    \n",
    "                transform = transforms.Normalize(task.statistics['mean'], [s if s>0 else s+1 for s in task.statistics['std']])\n",
    "            else:\n",
    "                transform.append(transforms.Normalize(task.statistics['mean'], [s if s>0 else s+1  for s in task.statistics['std']]))    \n",
    "\n",
    "    if single_head:\n",
    "        # adjust class labels for the single head regime\n",
    "        adjust_y=0\n",
    "        for t,old_t in enumerate(task_gen.task_pool):\n",
    "            if str(old_t.concepts)==str(task.concepts):\n",
    "                break\n",
    "            else:\n",
    "                adjust_y+=old_t.info()['n_classes'][0]           \n",
    "        y+=adjust_y \n",
    "    if args.shuffle_test and split!=0:\n",
    "        idx = torch.randperm(x.size(0))\n",
    "        x=x[idx]\n",
    "        y=y[idx]\n",
    "    \n",
    "    dataset = TensorDataset([x,y], transform)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=(split==0)) #or shuffle_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4452945-47b4-432b-ac1d-ff61e6c556ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('dev-2021-02-py38': venv)",
   "language": "python",
   "name": "python38564bitdev202102py38venved5311bfb7744d6caaf9ece0ad44c9d0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
